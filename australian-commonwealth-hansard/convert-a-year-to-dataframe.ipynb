{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a year's worth of Historic Hansard into a dataframe for analysis\n",
    "\n",
    "This notebook analyses Commonwealth Hansard XML files [from this GitHub repository](https://github.com/wragge/hansard-xml). Give it a `year` (between 1901 and 1980), and a `house` (either 'hofreps' or 'senate'), and it will download all the proceedings of that year and house, extract some basic data about debates and speeches, and provide the results as a dataframe for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_cache\n",
    "from bs4 import BeautifulSoup\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from tqdm.auto import tqdm\n",
    "import arrow\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "s = requests_cache.CachedSession()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[ 502, 503, 504 ])\n",
    "s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the GitHub API only allows 60 unauthorised requests per hour. So it's a good idea to cache things. Note that requests to download files aren't included in the API tally. If you need more requests you'll need to use authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = 'https://api.github.com/repos/wragge/hansard-xml/contents'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><img src=\"../images/hhicon.png\" width=\"50px\" style=\"vertical-align: bottom; margin-right: 10px;\">Just set the values below to a year and a house, then run all the cells!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '1901' # 1901 to 1980\n",
    "house = 'hofreps' # hofreps or senate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(para):\n",
    "    '''\n",
    "    Count the number of words in an element.\n",
    "    '''\n",
    "    words = 0\n",
    "    for string in para.stripped_strings:\n",
    "        words += len(string.split())\n",
    "    return words\n",
    "\n",
    "def get_paras(section):\n",
    "    '''\n",
    "    Find all the para type containers in an element and count the total number of words.\n",
    "    '''\n",
    "    words = 0\n",
    "    for para in section.find_all(['para', 'quote', 'list'], recursive=False):\n",
    "        words += count_words(para)\n",
    "    return words\n",
    "\n",
    "def get_words_in_speech(start, speech):\n",
    "    '''\n",
    "    Get the top-level containers in a speech and find the total number of words across them all.\n",
    "    '''\n",
    "    words = 0\n",
    "    words += get_paras(start)\n",
    "    words += get_paras(speech)\n",
    "    for cont in speech.find_all('continue', recursive=False):\n",
    "        cont_start = cont.find('talk.start', recursive=False)\n",
    "        words += get_paras(cont_start)\n",
    "        words += get_paras(cont)\n",
    "    return words\n",
    "                            \n",
    "def get_interjections(speech):\n",
    "    '''\n",
    "    Get details of any interjections within a speech.\n",
    "    '''\n",
    "    speeches = []\n",
    "    for index, intj in enumerate(speech.find_all('interjection', recursive=False)):\n",
    "        start = intj.find('talk.start', recursive=False)\n",
    "        speaker = start.find('talker')\n",
    "        name = speaker.find('name', role='metadata').string\n",
    "        id = speaker.find('name.id').string\n",
    "        words = get_words_in_speech(start, intj)\n",
    "        speeches.append({'interjection_idx': index, 'speaker': name, 'id': id, 'type': intj.name, 'words': words})\n",
    "    return speeches     \n",
    "\n",
    "def get_speeches(debate):\n",
    "    '''\n",
    "    Get details of any speeches in a debate (or subdebate)\n",
    "    '''\n",
    "    speeches = []\n",
    "    for index, speech in enumerate(debate.find_all(['speech', 'question', 'answer'], recursive=False)):\n",
    "        start = speech.find('talk.start', recursive=False)\n",
    "        speaker = start.find('talker')\n",
    "        name = speaker.find('name', role='metadata').string\n",
    "        id = speaker.find('name.id').string\n",
    "        words = get_words_in_speech(start, speech)\n",
    "        speeches.append({'speech_idx': index, 'speaker': name, 'id': id, 'type': speech.name, 'words': words})\n",
    "        # Interjections are within a speech\n",
    "        interjections = get_interjections(speech)\n",
    "        # Tag interjections with the speech index\n",
    "        for intj in interjections:\n",
    "            intj['speech_idx'] = index\n",
    "            speeches.append(intj)\n",
    "    return speeches\n",
    "\n",
    "def get_subdebates(debate):\n",
    "    '''\n",
    "    Get details of any subdebates within a debate.\n",
    "    '''\n",
    "    speeches = []\n",
    "    for index, sub in enumerate(debate.find_all('subdebate.1', recursive=False)):\n",
    "        subdebate_info = {'subdebate_title': sub.subdebateinfo.title.string, 'subdebate_idx': index}\n",
    "        new_speeches = get_speeches(sub)\n",
    "        # Add the subdebate info to the speech\n",
    "        for sp in new_speeches:\n",
    "            sp.update(subdebate_info)\n",
    "        speeches += new_speeches\n",
    "    return speeches\n",
    "\n",
    "def get_debates(soup):\n",
    "    '''\n",
    "    Get details of all the debates in day's proceedings.\n",
    "    '''\n",
    "    speeches = []\n",
    "    date = soup.find('session.header').date.string\n",
    "    for index, debate in enumerate(soup.find_all('debate')):\n",
    "        debate_info = {\n",
    "            'date': date,\n",
    "            'debate_title': debate.debateinfo.title.string,\n",
    "            'debate_type': debate.debateinfo.type.string,\n",
    "            'debate_idx': index\n",
    "        }\n",
    "        new_speeches = get_subdebates(debate)\n",
    "        new_speeches += get_speeches(debate)\n",
    "        # Add the debate info to the speech\n",
    "        for sp in new_speeches:\n",
    "            sp.update(debate_info)\n",
    "        speeches += new_speeches\n",
    "    return speeches\n",
    "\n",
    "def summarise_year(year, house):\n",
    "    '''\n",
    "    Get each day's proceedings for the supplied year/house and extract information about debates and speeches.\n",
    "    '''\n",
    "    speeches = []\n",
    "    response = s.get(f'{API_URL}/{house}/{year}')\n",
    "    data = response.json()\n",
    "    files = [f for f in data if f['type'] == 'file']\n",
    "    for f in tqdm(files):\n",
    "        response = s.get(f['download_url'])\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        speeches += get_debates(soup)\n",
    "    df = pd.DataFrame(speeches)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = summarise_year(year=year, house=house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who made the most speeches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['type'] == 'speech']['speaker'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who made the most interjections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['type'] == 'interjection']['speaker'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who spoke the most words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='speaker')['words'].sum().to_frame().reset_index().sort_values('words', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which debates generated the most words?\n",
    "\n",
    "Note that there's variation in the way debate titles were recorded, and in the OCR results, so this sort of grouping isn't always going to work. To get something more accurate, you'd have to do some normalisation of debate titles first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['debate_title'])['words'].sum().to_frame().reset_index().sort_values('words', ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many words were spoken each day of proceedings?\n",
    "\n",
    "I've only included words in speeches with identified speakers (including interjections), so some procedural content might not be included in the totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_per_day = df.groupby(by=['date'])['words'].sum().to_frame().reset_index()\n",
    "alt.Chart(words_per_day).mark_bar(size=2).encode(\n",
    "    x='date:T',\n",
    "    y='words:Q',\n",
    "    tooltip=['date:T', 'words:Q']\n",
    ").properties(width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular topics of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['debate_type'] == 'Questions') | (df['debate_title'] == 'QUESTION') | (df['type'] == 'question')]['subdebate_title'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Created by [Tim Sherratt](https://timsherratt.org) for the [GLAM Workbench](https://glam-workbench.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
